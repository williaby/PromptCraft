# [](#08-templates-and-basemodesmd)08 Templates-and-BaseModes.md

**Version:** Templates-BaseModes Document v2.0, June 2, 2025
**Source Document:** AI Prompt Engineering Guide: The C.R.E.A.T.E. Framework - v 1. (May 2025)
and PromptCraft Pro System Documents (00 Quick-Reference.md v2.1)
**Purpose:** This document provides a collection of templates, blueprints, and examples demonstrating
the structure of C.R.E.A.T.E. prompts generated by PromptCraft Pro. It also includes guidance on how
user inputs can leverage PromptCraft Pro's advanced features, and API skeletons for programmatic
interaction. These are designed to help users understand PromptCraft Pro's outputs and effectively
guide its prompt generation process.

## [](#table-of-contents)Table of Contents

1. [Introduction to Templates and Blueprints in the PromptCraft Pro Context](#introduction-to-templates-and-blueprints-in-the-promptcraft-pro-context)
2. [ANCHOR-TBM-1](#anchor-tbm-1)
3. [1. The Composite C.R.E.A.T.E. Blueprint (PromptCraft Pro Output Structure)](#1-the-composite-create-blueprint-promptcraft-pro-output-structure)
4. [# 1.1. Why Understanding the Blueprint Matters](#-11-why-understanding-the-blueprint-matters)
5. [# 1.2. How PromptCraft Pro Uses the Blueprint](#-12-how-promptcraft-pro-uses-the-blueprint)
6. [# 1.3. C.R.E.A.T.E. Prompt Blueprint (Illustrating PromptCraft Pro's Output)](#-13-create-prompt-blueprint-illustrating-promptcraft-pros-output)
7. [# 1.4. Starter Guided Template (Structured Input for PromptCraft Pro)](#-14-starter-guided-template-structured-input-for-promptcraft-pro)
8. [ANCHOR-TBM-2](#anchor-tbm-2)
9. [2. Base-Mode Blocks (Influencing PromptCraft Pro's Approach)](#2-base-mode-blocks-influencing-promptcraft-pros-approach)
10. [# 2.1. Why Base Modes Matter for User Input](#-21-why-base-modes-matter-for-user-input)
11. [# 2.2. How User Input Can Suggest Base Modes](#-22-how-user-input-can-suggest-base-modes)
12. [# 2.3. Overview of How Base Modes Influence Rigor and Techniques](#-23-overview-of-how-base-modes-influence-rigor-and-techniques)
13. [# 2.4. Example: Ultra-Concise User Input and PromptCraft Pro's Expansion](#-24-example-ultra-concise-user-input-and-promptcraft-pros-expansion)
14. [ANCHOR-TBM-3](#anchor-tbm-3)
15. [3. Domain-Specific C.R.E.A.T.E. Prompt Examples (Generated by PromptCraft Pro)](#3-domain-specific-create-prompt-examples-generated-by-promptcraft-pro)
16. [# 3.1. Overview of Domain-Specific Examples](#-31-overview-of-domain-specific-examples)
17. [# 3.2. Example: Code Generation Prompt (Illustrating Advanced Rigor)](#-32-example-code-generation-prompt-illustrating-advanced-rigor)
    1. [This example shows a C.R.E.A.T.E. prompt generated by PromptCraft Pro for a code generation task, likely at an "Advanced Rigor" (Level 3) due to the need for correctness and robustness](#this-example-shows-a-create-prompt-generated-by-promptcraft-pro-for-a-code-generation-task-likely-at-an-advanced-rigor-level-3-due-to-the-need-for-correctness-and-robustness)
18. [# 3.2. Example: Code Generation Prompt (Illustrating Advanced Rigor)](#-32-example-code-generation-prompt-illustrating-advanced-rigor-1)
19. [ANCHOR-TBM-4](#anchor-tbm-4)
20. [4. Understanding and Guiding PromptCraft Pro Effectively](#4-understanding-and-guiding-promptcraft-pro-effectively)
21. [ANCHOR-TBM-5](#anchor-tbm-5)
22. [5. API Skeletons for Programmatic Prompting with PromptCraft Pro Outputs](#5-api-skeletons-for-programmatic-prompting-with-promptcraft-pro-outputs)
23. [# 5.1. Purpose of API Level Prompting](#-51-purpose-of-api-level-prompting)
24. [# 5.2. Example API Call Skeleton (OpenAI) with a PromptCraft Pro Generated Prompt](#-52-example-api-call-skeleton-openai-with-a-promptcraft-pro-generated-prompt)

## [](#introduction-to-templates-and-blueprints-in-the-promptcraft-pro-context)Introduction to Templates and Blueprints in the PromptCraft Pro Context

In the PromptCraft Pro ecosystem, templates and blueprints serve two main functions:

1. To illustrate the structure and potential content of the sophisticated C.R.E.A.T.E. prompts that PromptCraft Pro
   generates.
2. To guide users on how to formulate their initial requests to PromptCraft Pro to achieve desired outcomes and
   leverage its advanced features.

These tools help users understand the power of the C.R.E.A.T.E. framework as implemented by PromptCraft Pro and how to
best interact with the system to produce high-quality prompts for downstream LLMs.

***

## [](#anchor-tbm-1)ANCHOR-TBM-1

## [](#1-the-composite-create-blueprint-promptcraft-pro-output-structure)1. The Composite C.R.E.A.T.E. Blueprint (PromptCraft Pro Output Structure)

## [](#-11-why-understanding-the-blueprint-matters)# 1.1. Why Understanding the Blueprint Matters

The C.R.E.A.T.E. Prompt Blueprint distills the entire C.R.E.A.T.E. workflow into a fillable structure. For users of
PromptCraft Pro, understanding this blueprint helps in interpreting the prompts generated by the system and in
providing effective initial input. It shows the comprehensive nature of prompts that PromptCraft Pro aims to build.

## [](#-12-how-promptcraft-pro-uses-the-blueprint)# 1.2. How PromptCraft Pro Uses the Blueprint

PromptCraft Pro takes a user's initial, often simple, request and elaborates it into a full C.R.E.A.T.E. prompt based on
this blueprint. It populates each section using its understanding of the user's need, information from its knowledge
base (like `00 Quick-Reference.md`), and its core instructions.

## [](#-13-create-prompt-blueprint-illustrating-promptcraft-pros-output)# 1.3. C.R.E.A.T.E. Prompt Blueprint (Illustrating PromptCraft Pro's Output)

*(This blueprint illustrates the comprehensive structure of a C.R.E.A.T.E. prompt as typically generated by PromptCraft
Pro. Placeholders `[...]` indicate where specific content, often derived from user input or `00 Quick-Reference.md`
ANCHORs, will be inserted by PromptCraft Pro.)*

````markdown
## # C.R.E.A.T.E. Prompt ###

**C - Context:**
You are a **[Role and Persona clause, e.g., "seasoned econometrician, specializing in dynamic scoring models for fiscal policy"]** *(Instruction: From ANCHOR-QR-0)*.
The background is **[Synthesized background information relevant to the request, including key facts, scope, and any provided documents/URLs by the user. Example: "analyzing the ten-year macroeconomic impact of H.R. 1234, a proposed carbon tax."]**
The goal is **[User's primary goal/intent for the output, clarified and articulated by PromptCraft Pro. Example: "to produce a rigorous, unbiased estimate of fiscal and economic effects for a legislative committee."]**
The target audience is **[Specific audience if defined, otherwise default from ANCHOR-QR-0, e.g., "technical staff at the Congressional Budget Office"]**.

**R - Request:**
[User's core task, precisely restated by PromptCraft Pro. Example: "Draft a **Tier 6: In-Depth Analysis** (approx. 2,000-5,000 words) evaluating H.R. 1234."]* (Tier from ANCHOR-QR-2)*.
*(Instruction: If task implies >= 3 logical steps, PromptCraft Pro adds: "Chain = ON: Provide mini-state summaries after each logical step for clarity.")*

**E - Examples:**
*(Instruction: If user provided suitable examples, PromptCraft Pro inserts them here, structured clearly.)*
*(Instruction: If no user examples are provided, PromptCraft Pro inserts: `(N/A: R and T specify format.)` or a generic structural placeholder like `Example: 1. <Item> - <1-2 sentence description>` if illustrative structure is deemed beneficial by PromptCraft Pro.)*

**A - Augmentations:**
*(Instructions for the downstream LLM, assembled by PromptCraft Pro)*
> “Internal analysis only. No external tools/searches unless web.search_query specified.”
> “Use CoT/ToT reasoning. Hide steps; show final answer only, unless user asks. (Enhance via ANCHOR-QR-11 #8 if chosen).”
> “If structured analysis implied, consider/state framework (e.g., SWOT/IRAC per `04 Framework-Library.md`).” *(Example: "Apply the 'Dynamic Scoring per CBO' framework.")*
> “Attribute claims to sources. For inferred/synthesized claims, append `[ExpertJudgment]`.”
> “Strictly follow E-block evaluation protocols (inc. reflection).”

*(Instruction: If Rigor Level (ANCHOR-QR-10) is Intermediate (L2) or Advanced (L3), PromptCraft Pro copies Factual Accuracy and Bias Mitigation Directives from ANCHOR-QR-13 here.)*
> *(Example if QR-13 is included: "Prioritize factual accuracy rigorously... Strive for neutral, objective language...")*

*(Instruction: Based on Rigor Level, user request, inference, or Tier, PromptCraft Pro copies selected verbatim instructions from ANCHOR-QR-11 here.)*
> *(Example if ANCHOR-QR-11 #2 Self-Consistency is selected: "For this task, if it involves complex reasoning... employ Self-Consistent Sampling...")*

*(Instruction: If Live-Data Policy for the request is Volatile, PromptCraft Pro applies ANCHOR-QR-1 here.)*
> *(Example if QR-1 is applied: Instructions to use `web.search_query` and cite per ANCHOR-QR-1a.)*

**T - Tone and Format:**
*(Instruction: PromptCraft Pro copies all 7 stylometry lines from ANCHOR-QR-7 verbatim here first.)*
- Hedge Density: 5-10 %. (See ANCHOR-QR-3)
- Lexical Diversity: TTR >= 0.40; no word > 2 % tokens; avoid clichés. (See ANCHOR-QR-4)
- Sentence Variability: Avg 17-22 words; >= 15 % sentences < 8 words; >= 15 % sentences > 30 words; sigma >= 8. (See ANCHOR-QR-5)
- Rhetorical Devices: >= 1 rhetorical question AND >= 1 first-person or direct-address aside.
- Paragraph Pacing: Mix short (2-3 sentences) and long (4-6+ sentences) paragraphs with smooth transitions.
- Conversational Tone: Use contractions; **no em-dashes;** only use bullet/number lists if explicitly requested by the user.
- Punctuation and Structure: Use commas for asides; colons for expansion; semicolons for linked clauses; narrative prose only (no lists unless requested).

*(Instruction: Then, PromptCraft Pro inserts dynamic specifications based on user input or inference, informed by
`06 Tone-and-Format.md`):*
```text

Tone: [Example: "Formal / Scholarly; maintain objective neutrality"]
Format: [Example: "Narrative prose with H2 for major sections and H3 for sub-sections.
Use Markdown tables for quantitative comparisons."]
Citation Style: [Example: "Bluebook (21st ed.) using footnotes for all citations."]

```text

**E - Evaluation:**
*(Instruction: PromptCraft Pro copies ANCHOR-QR-8 verbatim here, including its E.1-E.6 steps and the standard Evaluation Footer.)*
`E.1 Reflection Loop: Draft response -> list <= 3 critical weaknesses, gaps, or potential errors based on all
C.R.E.A.T.E. requirements; formulate a plan to address them -> revise draft once to implement plan. If critical
issues persist or new ones are introduced, flag output with [NeedsHumanReview] and briefly state unresolved issues.
(This loop may be enhanced by ANCHOR-QR-11 item #1 if selected by PromptCraft Pro).`
`E.2 Self-Consistency Check: If the request involves critical numerical outputs, key factual extractions, or
complex logical deductions, internally generate 2-3 diverse reasoning paths (using a slightly varied approach or
temperature if possible) to the key conclusions. If significant discrepancies arise between paths for a critical
output, flag that output with [LowConsensus] and present the most common or highest-confidence result if
discernible, otherwise state the discrepancy.`
`E.3 Chain-of-Verification (CoVe): For any complex factual claims, sequences of events, or
multi-step logical arguments: (a) Internally formulate 1-2 verification questions for each critical
component/step. (b) Internally answer these verification questions. (c) Review answers; if any
contradiction or unsupported element is found, revise the original claim/argument to ensure accuracy
and support, or flag with [VerificationIssue].`
`E.4 Confidence, Sourcing and Accuracy Assertion: For every primary factual assertion or significant
conclusion: a. **Verify Source Adherence:** Ensure it is directly and accurately attributable to provided
source material if sources were given. Cite explicitly if required by prompt. b. **Tag Inferences:** If the
assertion is an inference, synthesis, or based on general knowledge not present in provided sources, it
MUST be tagged \`[ExpertJudgment]\`. c. **Assess and Declare Confidence:** If confidence in a claim is
notably low due to ambiguity in sources, lack of definitive information, complex inference, or issues
identified in E.2 (Self-Consistency) or E.3 (CoVe), it MUST be flagged with \`[Confidence:Low]\` and a
brief (internal or explicit if requested) reason noted (e.g., "conflicting source data," "multi-step
inference with assumptions"). Unverifiable critical claims should be flagged \`[DataUnavailableOrUnverified]\`
or omitted if accuracy is paramount. Use appropriate hedging in language for low-confidence statements.`
`E.5 Style, Safety and Constraint Pass: Verify strict adherence to all T-block stylometry directives
(ANCHOR-QR-7) and any specific formatting or negative constraints from the A-block (e.g., "Do not discuss X").
Confirm no PII, harmful, or biased content is present. If any stylistic or safety/constraint rule is violated
and cannot be rectified in the reflection loop, flag with [StyleSafetyFail].`
`E.6 Overall Fitness and Final Review: Before concluding, perform a final check that the entire response
holistically addresses all aspects of the R-block, is coherent, and meets the overall quality standards
implied by the C.R.E.A.T.E. framework. If significant concerns remain after all checks, prepend the response
with [OverallQualityConcern].`

`Evaluation Footer:`
`**Suggested Tier:** Tier X  |  **OK?** (yes / choose another)`
`**Other changes?** (add / delete / tweak any C-R-E-A-T-E block before we finalise)`

*(Instruction: After ANCHOR-QR-8, PromptCraft Pro appends relevant prompt-specific checks, guided by ANCHOR-QR-12.)*
*(Example of a prompt-specific check from ANCHOR-QR-12):*
`* If Numerical UQ (ANCHOR-QR-11 #5) was instructed, verify that [Confidence: XX/100] scores accompany key claims.`
````

## [](#-14-starter-guided-template-structured-input-for-promptcraft-pro)# 1.4. Starter Guided Template (Structured Input for PromptCraft Pro)

**Purpose:** This template provides a structured way for users to quickly provide their core needs to **PromptCraft Pro**. It is **not** a C.R.E.A.T.E. prompt itself, but rather a simplified input format. PromptCraft Pro will parse this input and use it to construct a comprehensive, C.R.E.A.T.E.-compliant prompt according to the full blueprint (see Section 1.3).

**How to use:** Replace every angle-bracketed note (`<...>`) with your own content. Send the entire block as your initial request to PromptCraft Pro. PromptCraft Pro will then engage with you to refine this into a full C.R.E.A.T.E. prompt.

```markdown
## # C Context Input
* Topic -> <e.g., Oregon municipal bond tax treatment for non-residents>
* Audience -> <e.g., Financial advisors briefing their clients>
* Ambiguity Flag -> <e.g., "Unclear how recent federal changes to Section103 affect state-level interpretation for bonds issued after 2024.">

## # R Role Input
<e.g., "You are 'Samantha'-a warm, highly analytical tax policy expert known for clear explanations to professionals.">
*(PromptCraft Pro will convert this to the standard "You are a seasoned..." format from ANCHOR-QR-0)*

## # E Expectations Input
* Desired Voice -> <e.g., Precise, authoritative yet accessible, lightly humorous if appropriate; contractions OK.>
* Desired Structure -> <e.g., Use H2 for main topics, H3 for sub-topics; allow one bullet list per H2 section if it aids clarity.>
* Desired Depth -> <e.g., "Extended Overview (Tier 5, aiming for ~1500 words). Structure: 10% Intro/Exec Summary, 70% Core Analysis and Examples, 10% Implications/Next Steps, 10% References (if any).">

## # A Approach Input (User's preferences for how the downstream LLM should work)
1. <e.g., "Prioritize applying the 'IRC Pathway Map' framework.">
2. <e.g., "Employ methodical Chain-of-Thought or Tree-of-Thought reasoning; this reasoning should be hidden in
   the final output.">
3. <e.g., "Given the ambiguity flagged, please ask clarifying questions until approximately 95% confident
   you can fulfill the request accurately." -> This will trigger PromptCraft Pro to instruct the downstream LLM
   to use "Prompt Interrogation Chains" from ANCHOR-QR-11 #3.>
4. <e.g., "For this sensitive topic, I prefer Advanced Rigor." -> This informs PromptCraft Pro's Rigor Level
   selection (ANCHOR-QR-10).>

## # T Tools Input
* <e.g., "Use `web.search_query` to find relevant state tax bulletins or analyses issued in the last 12 months.">
* <e.g., "Use `python_user_visible` to generate a comparative table if helpful.">

## # E Evaluation Input (User's desires for how the downstream LLM should self-evaluate)
* <e.g., "Citations should be in superscript Chicago footnote style. Please flag any reliance on non-primary sources like blogs or forums.">
* <e.g., "Ensure all inferred statements are tagged `[Expert Judgment]`.">
* <e.g., "Given the complexity, please apply enhanced self-consistency checks to numerical or specific legal interpretations.">
*(PromptCraft Pro will translate these desires into the standard ANCHOR-QR-8 E-block, plus relevant prompt-specific checks guided by ANCHOR-QR-12, and may invoke specific advanced techniques from ANCHOR-QR-11 (like Self-Consistency or Numerical UQ) based on these inputs. The T-block will specify the citation style.)*
```

**How PromptCraft Pro Uses This Input:**

* **Context/Role/Expectations Input:** Used by PromptCraft Pro to populate the C, R, and T blocks of the final
  C.R.E.A.T.E. prompt, aligning with `ANCHOR-QR-0` for role and default audience.
* **Approach Input:** Informs PromptCraft Pro's selection of Rigor Level (`ANCHOR-QR-10`), specific analytical
  frameworks (from `04 Framework-Library.md`), and Advanced Evaluation and Reasoning Techniques (`ANCHOR-QR-11`)
  for the A-block of the C.R.E.A.T.E. prompt. For instance, requesting "95% confident" directly maps to using
  `ANCHOR-QR-11 #3` (Prompt Interrogation Chains).
* **Tools Input:** Informs the Augmentations block regarding live data tools (potentially invoking `ANCHOR-QR-1`).
* **Evaluation Input:** Guides PromptCraft Pro in ensuring the standard `ANCHOR-QR-8` E-block is robust and in
  adding necessary prompt-specific checks (using guidance from `ANCHOR-QR-12`). It may also trigger the inclusion
  of specific advanced evaluation techniques from `ANCHOR-QR-11` and ensures the T-block specifies the correct
  citation style.

***

## [](#anchor-tbm-2)ANCHOR-TBM-2

## [](#2-base-mode-blocks-influencing-promptcraft-pros-approach)2. Base-Mode Blocks (Influencing PromptCraft Pro's Approach)

## [](#-21-why-base-modes-matter-for-user-input)# 2.1. Why Base Modes Matter for User Input

Base modes refer to general operational contexts or standardized task types (e.g., "Python-Focused Mode," "Data-Centric Mode"). When a user's request aligns with a known base mode, it can help PromptCraft Pro more effectively determine appropriate default settings, such as the Rigor Level or relevant Advanced Techniques.

## [](#-22-how-user-input-can-suggest-base-modes)# 2.2. How User Input Can Suggest Base Modes

Users don't typically state "use Python-Focused Mode." Instead, the nature of their request (e.g., "Generate a Python script to parse...") implies this mode to PromptCraft Pro. PromptCraft Pro uses its understanding of these modes (informed by this knowledge file and potentially other specific training) to make better decisions about the C.R.E.A.T.E. prompt structure.

## [](#-23-overview-of-how-base-modes-influence-rigor-and-techniques)# 2.3. Overview of How Base Modes Influence Rigor and Techniques

When PromptCraft Pro recognizes that a user's request falls into a common base mode, it may adjust its approach:

* **Python-Focused Mode:** Implied by requests for Python code generation, review, or debugging.
  * *Potential Influence:* Suggests PromptCraft Pro apply Intermediate or Advanced Rigor Level (`ANCHOR-QR-10`). May trigger advanced techniques like `ANCHOR-QR-11 #2` (Self-Consistency for code logic/outputs) or `ANCHOR-QR-11 #8` (Stepwise NL Self-Critique for algorithm design and implementation steps).
* **Data-Centric Mode:** Implied by requests for data analysis, cleaning, visualization, or interpretation.
  * *Potential Influence:* May suggest Intermediate Rigor (`ANCHOR-QR-10`), focusing on techniques like `ANCHOR-QR-11 #4` (Advanced Error Forecasting for data quality issues or misinterpretations) and ensuring robust `ANCHOR-QR-8 E.3` (CoVe for data transformations and analytical steps).
* **Meta-Prompt Mode:** Implied when the user asks PromptCraft Pro to generate narrative guides, tutorials, or extensive explanatory text (often about prompting itself or complex topics).
  * *Potential Influence:* Rigor Level will vary significantly based on the complexity and stakes of the meta-prompt's subject. May utilize `ANCHOR-QR-11 #3` (Prompt Interrogation) to ensure clarity and `ANCHOR-QR-11 #8` (Stepwise NL Self-Critique) for structuring complex explanations.
* **Presentation-Slide Mode:** Implied by requests to generate content for slides (e.g., "5x5 rule").
  * *Potential Influence:* Typically suggests Basic Rigor (`ANCHOR-QR-10`), with a strong focus on T-block formatting constraints and conciseness.
* **General QA/Review Mode:** While evaluation is always active via `ANCHOR-QR-8`, if a user's request is *primarily* to review or critique an existing piece of text or code, PromptCraft Pro would emphasize evaluation techniques, potentially at a higher Rigor Level and selecting relevant methods from `ANCHOR-QR-11` (like #1, #4, #7, or #8).

## [](#-24-example-ultra-concise-user-input-and-promptcraft-pros-expansion)# 2.4. Example: Ultra-Concise User Input and PromptCraft Pro's Expansion

This section illustrates how a user might provide a very brief initial request, potentially using a shorthand or "baseline" set of preferences. PromptCraft Pro's role is to parse this, ask clarifying questions if essential details are missing (guided by its own instructions, potentially invoking `ANCHOR-QR-11 #3` for itself), and then expand it into a full C.R.E.A.T.E. prompt.

**User Input Example (emulating the old "OneLine Append Block"):**
`"Summarize the attached report on renewable energy trends. My preferences: Persona Samantha (warm, analytical). Voice precise and clear, burstiness 12-24w. Tier 4 Overview. Think CoT/ToT; ask questions until 95% sure. Cite superscript Chicago; tag unsourced [Expert Judgment]. Warn on PII; add ===CONTINUE=== if output nears limit."`

**PromptCraft Pro's Action (Conceptual):**

1. **Parse Input:** Identify core request ("Summarize report"), persona ("Samantha..."), voice preferences, desired Tier ("Tier 4"), reasoning approach ("CoT/ToT, ask until 95% sure"), citation style ("superscript Chicago"), `[Expert Judgment]` tagging, and other guardrails.
2. **Determine Rigor Level:** Based on "Tier 4" and "ask until 95% sure," PromptCraft Pro might default to Intermediate Rigor (Level 2 from `ANCHOR-QR-10`).
3. **Select Advanced Techniques:** "ask until 95% sure" strongly implies `ANCHOR-QR-11 #3` (Prompt Interrogation Chains). The request for CoT/ToT reasoning is a core directive.
4. **Construct C.R.E.A.T.E. Prompt:**
   * **C-Block:** Role based on "Samantha (warm, analytical)" transformed per `ANCHOR-QR-0`. Background from "attached report." Goal "Summarize for user."
   * **R-Block:** "Draft a Tier 4: Overview (approx. 400-900 words) summarizing the key findings and implications of the attached report on renewable energy trends."
   * **A-Block:** Include core directives (CoT/ToT, Expert Judgment). Add verbatim instructions from `ANCHOR-QR-11 #3`. If Intermediate Rigor also implies, e.g., `ANCHOR-QR-13` Factual Accuracy/Bias directives, those would be added.
   * **T-Block:** Start with `ANCHOR-QR-7`. Then: `Tone: Warm, analytical, precise, clear. Sentence Variability: (parameters for 12-24w burstiness if different from QR-7 default). Citation Style: Chicago superscript footnotes.`
   * **E-Block:** `ANCHOR-QR-8` verbatim, plus prompt-specific checks from `ANCHOR-QR-12` (e.g., verify "ask until 95% sure" was actioned, check word count, ensure `[Expert Judgment]` used).
5. **User Interaction:** Present the generated C.R.E.A.T.E. prompt and the Tier/Rigor feedback.

***

## [](#anchor-tbm-3)ANCHOR-TBM-3

## [](#3-domain-specific-create-prompt-examples-generated-by-promptcraft-pro)3. Domain-Specific C.R.E.A.T.E. Prompt Examples (Generated by PromptCraft Pro)

## [](#-31-overview-of-domain-specific-examples)# 3.1. Overview of Domain-Specific Examples

The following are illustrative examples of complete C.R.E.A.T.E. prompts as they might be *generated by PromptCraft Pro* for specific types of tasks. They demonstrate how the blueprint from Section 1.3 is populated, including the conditional inclusion of advanced features based on an inferred or specified Rigor Level.

## [](#-32-example-code-generation-prompt-illustrating-advanced-rigor)# 3.2. Example: Code Generation Prompt (Illustrating Advanced Rigor)

### [](#this-example-shows-a-create-prompt-generated-by-promptcraft-pro-for-a-code-generation-task-likely-at-an-advanced-rigor-level-3-due-to-the-need-for-correctness-and-robustness)This example shows a C.R.E.A.T.E. prompt generated by PromptCraft Pro for a code generation task, likely at an "Advanced Rigor" (Level 3) due to the need for correctness and robustness

## [](#-32-example-code-generation-prompt-illustrating-advanced-rigor-1)# 3.2. Example: Code Generation Prompt (Illustrating Advanced Rigor)

Below is an illustrative C.R.E.A.T.E. prompt for generating a Python function.

````markdown
## # C.R.E.A.T.E. Prompt ###

**C - Context:**
You are a **Senior Python Developer, specializing in secure and efficient financial data processing algorithms** *(Instruction: From ANCHOR-QR-0)*.
The background is a requirement to process Xero-exported CSV files containing monthly transaction data for a small business client. The goal is to accurately calculate total revenue per month for financial reporting.
The target audience is **fellow developers and the client's accounting team**.

**R - Request:**
Draft a **Tier 3: Concise Summary** (approx. 150-400 words) and provide a Python 3.11 function that reads a CSV file of transactions (with columns 'date' and 'amount') and returns a summary dictionary mapping each month to its total revenue.

**E - Examples:**
Example CSV content:
```csv
date,amount
2024-01-01,1000.50
2024-01-15,500.00
2024-02-01,-75.25
2024-02-20,300.75
```csv
Example output:
```python
{'2024-01': 1500.50, '2024-02': 225.50}
```python
Example text subset:
```text
This function should include error handling and proper comments.
```text

**A - Augmentations:**
> “Internal analysis only. No external tools/searches unless specified.”
> “Use CoT/ToT reasoning. Hide steps; show final answer only.”

**T - Tone and Format:**
```text
Tone: [Technical, Precise, Professional]
Format: [Brief explanation followed by a single Python code block.]
Citation Style: [N/A]
```text

**E - Evaluation:**
`E.1 Reflection Loop: Draft response -> list up to 3 critical weaknesses...`
`E.2 Self-Consistency Check: Generate 2-3 reasoning paths...`
`Evaluation Footer: **Suggested Tier:** Tier X  |  **OK?** (yes / choose another)`
````

*(Further examples for 3.3 Schema Extraction and 3.4 Multimodal Analysis would follow a similar pattern, updated to the new blueprint, showing different Rigor Levels and correspondingly different selections from ANCHOR-QR-11 and ANCHOR-QR-13.)*

***

## [](#anchor-tbm-4)ANCHOR-TBM-4

## [](#4-understanding-and-guiding-promptcraft-pro-effectively)4. Understanding and Guiding PromptCraft Pro Effectively

Instead of manually assembling C.R.E.A.T.E. components, users now interact with PromptCraft Pro
to achieve a well-structured final prompt. Here’s how to make that interaction effective:

1. **Understand the Output Structure (Section 1.3 Blueprint):** Familiarize yourself with the
   comprehensive C.R.E.A.T.E. prompt structure that PromptCraft Pro aims to generate. This
   helps you understand what information it might need and why it asks certain clarifying questions.
2. **Provide Clear Initial Input:** Use the "Starter Guided Template" (Section 1.4) or a clear
   natural language request. The more specific your initial input regarding Topic, Audience,
   fesired Role, Expectations (Voice, Structure, Depth), preferred Approach (reasoning,
   confidence levels), Tools, and Evaluation criteria, the better PromptCraft Pro can tailor its output.
3. **Leverage Rigor Levels:** If you know your task requires high robustness, ask PromptCraft
   Pro to use an "Intermediate" or "Advanced" Rigor Level. This will automatically trigger more
   sophisticated augmentation and evaluation instructions (from `ANCHOR-QR-10` and
   `ANCHOR-QR-11`) in the generated prompt.
4. **Request Specific Advanced Techniques:** If you are familiar with the techniques in
   `ANCHOR-QR-11` (e.g., Self-Consistency, Prompt Interrogation), you can explicitly ask
   PromptCraft Pro to include instructions for them in the generated prompt.
5. **Iterate with PromptCraft Pro:** Use the feedback mechanism to refine the C.R.E.A.T.E.
   prompt that PromptCraft Pro generates. Ask for tweaks to specific blocks if needed.
6. **Consult Supporting Knowledge Files:** Refer to `01 Context-Blocks.md` through `07
   Evaluation-Toolkit.md` to understand the details behind each C.R.E.A.T.E. component and the
   available options (e.g., different tones from `06 Tone-and-Format.md`, available frameworks
   from `04 Framework-Library.md`).

**Pro-Tips for Managing PromptCraft Pro Interactions and Outputs:**

* **Mapping Matrix:** Maintain a personal or team Notion/Wiki matrix linking types of user
  requests to the Rigor Levels and Advanced Techniques PromptCraft Pro typically applies. This
  helps build institutional knowledge.
* **Onboarding:** New staff can start by providing simpler inputs and observing how PromptCraft
  Pro builds the C.R.E.A.T.E. prompt, then gradually learn to guide it more specifically.
* **Version Control for Inputs:** If you develop standard inputs for PromptCraft Pro (like
  filled "Starter Guided Templates" for recurring tasks), store these in Git.
* **Library of Generated Prompts:** Save particularly effective C.R.E.A.T.E. prompts generated
  by PromptCraft Pro in a shared library (e.g., Notion), tagged by task type, Rigor Level used,
  and key Advanced Techniques invoked. This creates a valuable repository of "gold-standard" prompts.

***

## [](#anchor-tbm-5)ANCHOR-TBM-5

## [](#5-api-skeletons-for-programmatic-prompting-with-promptcraft-pro-outputs)5. API Skeletons for Programmatic Prompting with PromptCraft Pro Outputs

## [](#-51-purpose-of-api-level-prompting)# 5.1. Purpose of API Level Prompting

While PromptCraft Pro assists in generating high-quality C.R.E.A.T.E. prompts, these prompts
are ultimately intended for use with downstream LLMs, often via their APIs. APIs allow granular
control over model parameters (like temperature, max\_tokens) crucial for tuning the final output.

## [](#-52-example-api-call-skeleton-openai-with-a-promptcraft-pro-generated-prompt)# 5.2. Example API Call Skeleton (OpenAI) with a PromptCraft Pro Generated Prompt

The following Python snippet illustrates how a C.R.E.A.T.E. prompt, *once generated and
finalized with PromptCraft Pro*, can be used in an API call to a downstream LLM (e.g., an OpenAI model).

````python
# Ensure you have the OpenAI library installed: pip install openai
# And your API key is set as an environment variable: OPENAI_API_KEY

from openai import OpenAI

client = OpenAI()

# This full_create_prompt would be the output from PromptCraft Pro
full_create_prompt = """
## # C.R.E.A.T.E. Prompt ###

**C - Context:**
You are a **seasoned financial analyst, specializing in renewable energy project viability for institutional investors** *(Instruction: From ANCHOR-QR-0)*.
The background is a detailed prospectus for a new utility-scale solar farm project ("Project Sunbeam") seeking $50M in Series B funding. Key data includes projected kWh output, PPA agreements, and EPC contractor details.
The goal is to produce an independent assessment of Project Sunbeam's financial risks and potential ROI over 15 years for an investment committee.
The target audience is **the investment committee members, who are financially savvy but may not be renewable energy experts**.

**R - Request:**
Draft a **Tier 6: In-Depth Analysis** (approx. 3000-4000 words) of Project Sunbeam's financial viability, focusing on risk-adjusted ROI. *(Tier from ANCHOR-QR-2)*.
Chain = ON: Provide mini-state summaries after each major analytical section (e.g., Market Risk, Operational Risk, Financial Projections, ROI Analysis).

**E - Examples:**
(N/A: R and T specify format.)

**A - Augmentations:**
*(Instructions for the downstream LLM)*
> “Internal analysis only. No external tools/searches unless web.search_query specified.”
> “Use CoT/ToT reasoning. Hide steps; show final answer only, unless user asks. (Enhance via ANCHOR-QR-11 #8 if chosen).”
> “If structured analysis implied, consider/state framework (e.g., SWOT/IRAC per `04 Framework-Library.md`).” *(Instruction: Apply a standard financial risk assessment framework, explicitly detailing assumptions for discount rates and energy price forecasts.)*
> “Attribute claims to sources. For inferred/synthesized claims, append `[ExpertJudgment]`.”
> “Strictly follow E-block evaluation protocols (inc. reflection).”

*(Instruction: Rigor Level is Advanced (L3), PromptCraft Pro includes ANCHOR-QR-13 verbatim.)*
> “Prioritize factual accuracy rigorously. If uncertain about a fact not directly verifiable from provided sources, explicitly state the uncertainty (e.g., using `[Confidence:Low]` as per E-block E.4 or `[DataUnavailableOrUnverified]`) or, if appropriate for the request's integrity, omit the speculative claim. Cross-verify critical facts if possible using internal knowledge, but always give precedence to provided source documents and clearly attribute information.”
> “Strive for neutral, objective language. Actively identify and rephrase any statements that could be perceived as biased due to loaded terminology, promoting stereotypes, or presenting unbalanced perspectives, unless the requested persona explicitly requires a specific viewpoint (in which case, a flag like `[PersonaViewpoint:OptimisticProjectionAsInstructed]` might be used for investor-focused sections if requested, but core risk analysis remains objective). Ensure diverse perspectives are considered if the topic is sensitive or multifaceted, unless the prompt specifically narrows the focus.”

*(Instruction: Selected Advanced Techniques for Advanced Rigor financial analysis from ANCHOR-QR-11 by PromptCraft Pro):*
> *(Instruction from ANCHOR-QR-11 #1 - Enhanced Reflection Loop Controls, with Max Iterations=3, Focus Areas on financial model accuracy, risk identification, and clarity for investors)*
> *(Instruction from ANCHOR-QR-11 #5 - Robust UQ Numerical Scoring, applied to key financial projections and ROI figures: `[Confidence: XX/100]`)*
> *(Instruction from ANCHOR-QR-11 #4 - Advanced Error Forecasting, focusing on `[ErrorForecast:CalculationError]`, `[ErrorForecast:AssumptionUnsupported]`, `[ErrorForecast:MarketMisread]`).*

**T - Tone and Format:**
*(Instruction: ANCHOR-QR-7 verbatim lines included here by PromptCraft Pro)*
- Hedge Density: 5-10 %. (See ANCHOR-QR-3)
- (The other 6 lines from ANCHOR-QR-7)
```text

Tone: [Formal, Analytical, Objective, with clarity for financially savvy but non-expert audience]
Format: [Report structure with clear H2 sections for Introduction, Market Analysis, Operational Risk Assessment, Financial Projections (including key tables for cash flow, IRR, NPV), ROI Analysis and Sensitivities, Conclusion. Use Markdown for tables.]
Citation Style: [If external market reports are referenced (via hypothetical web search or provided docs), use 'Author (Year)' inline and a full reference list.]

```text
**E - Evaluation:**
*(Instruction: ANCHOR-QR-8 verbatim copied here by PromptCraft Pro, including E.1-E.6 and standard Evaluation Footer)*
`E.1 Reflection Loop: ... (Execution modified by ANCHOR-QR-11 #1).`
`E.2 Self-Consistency Check: ... (To be applied to key calculations like NPV, IRR).`
`E.3 Chain-of-Verification (CoVe): ... (To be applied to assumptions underpinning financial models).`
`E.4 Confidence, Sourcing and Accuracy Assertion: ... (Numerical confidence required due to ANCHOR-QR-11 #5).`
`E.5 Style, Safety and Constraint Pass: ...`
`E.6 Overall Fitness and Final Review: ...`

`Evaluation Footer:`
`**Suggested Tier:** Tier X  |  **OK?** (yes / choose another)`
`**Other changes?** (add / delete / tweak any C-R-E-A-T.E block before we finalise)`

*(Instruction: PromptCraft Pro appends prompt-specific checks from ANCHOR-QR-12.)*
* Verify all financial models (NPV, IRR, cash flow) are internally consistent and clearly explained.
* Ensure risk assessment adequately covers market, operational, and financial risks with mitigation strategies.
* Confirm `[Confidence: XX/100]` scores are present for all key projections.
* Check for `[ErrorForecast:...]` tags and ensure they were addressed or justified.
* Ensure conclusions on ROI are directly supported by the analysis presented.
"""

try:
  completion = client.chat.completions.create(
    model="gpt-4-turbo", # Or your preferred downstream LLM
    messages=[
      # No system prompt here, as the C.R.E.A.T.E. prompt's C-block defines the role.
      # Some API users prefer a very light system prompt like "You are a helpful AI assistant."
      # For C.R.E.A.T.E., it's often better to let the C-block fully drive the persona.
      {"role": "user", "content": full_create_prompt}
    ],
    temperature=0.2,       # Lower for more factual/deterministic tasks
    # top_p=1.0,           # Default
    max_tokens=4090,       # Adjust based on expected output length and model limits
    # stop=["###", "---"] # Optional stop sequences
  )

  llm_response = completion.choices[0].message.content
  print("Downstream LLM Response:\n", llm_response)
  # Further processing of llm_response, e.g., checking for flags like [NeedsHumanReview]

except Exception as e:
  print(f"An API error occurred: {e}")
````
